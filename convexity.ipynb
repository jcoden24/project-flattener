{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "parental-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-japan",
   "metadata": {},
   "outputs": [],
   "source": [
    "aust_yld_crv =  [\n",
    "                (datetime.date(2022,9,20),-0.73),\n",
    "                (datetime.date(2023,7,15),-0.745),\n",
    "                (datetime.date(2024,7,15),-0.731),\n",
    "                (datetime.date(2025,10,20),-0.715),\n",
    "                (datetime.date(2026,10,20),-0.635),\n",
    "                (datetime.date(2027,4,20),-0.600),\n",
    "                (datetime.date(2028,2,20),-0.516),\n",
    "                (datetime.date(2029,2,20),-0.403),\n",
    "                (datetime.date(2030,2,20),-0.319),\n",
    "                (datetime.date(2031,2,20),-0.234),\n",
    "                (datetime.date(2037,3,15),0.026),\n",
    "                (datetime.date(2040,10,20),0.222),\n",
    "                (datetime.date(2047,2,20),0.295),\n",
    "                (datetime.date(2051,3,20),0.36065),\n",
    "                (datetime.date(2062,1,26),0.466),\n",
    "                (datetime.date(2086,11,2),0.655),\n",
    "                (datetime.date(2120,6,30),0.806103),\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bond():\n",
    "    def __init__(self, acc, mat, cpn, yld, c_dt=datetime.date(2021, 8, 6)):\n",
    "        '''\n",
    "        acc = first interest accrual date\n",
    "        mat = maturity date\n",
    "        cpn = coupon in percent\n",
    "\n",
    "        c_dt = current date\n",
    "        yld = yield in percent\n",
    "        '''\n",
    "        self.acc = acc\n",
    "        self.mat = mat\n",
    "        self.cpn = cpn\n",
    "        self.tenor = mat.year - acc.year\n",
    "        self.cpn_dates = self.get_cpn_dates()\n",
    "        self.yld = yld\n",
    "        self.c_dt = c_dt\n",
    "\n",
    "    def get_cpn_dates(self):\n",
    "        '''\n",
    "        Output: list of cpn payment dates using first accrual, assume Act/Act Annual\n",
    "        '''\n",
    "        return [datetime.date(self.acc.year + i + 1, self.acc.month, self.acc.day) for i in range(self.tenor)]\n",
    "\n",
    "    def get_discount_factors(self):\n",
    "        '''\n",
    "        Output: list of discount factors from cpn_dates, assuming flat yield\n",
    "        '''\n",
    "        val_cpn_dates = [i for i in self.cpn_dates if i > self.c_dt]\n",
    "        year_frac = [(i - self.c_dt).days / 365. for i in val_cpn_dates]\n",
    "        discount_rates = [self.yld / 100.] * len(val_cpn_dates)\n",
    "        return [1 / ((1 + discount_rates[i]) ** year_frac[i]) for i in range(len(year_frac))]\n",
    "\n",
    "    def dirty_px(self):\n",
    "        '''\n",
    "        Inputs: c_dt, maturity, cpn, yld\n",
    "        Output: dirty price\n",
    "        '''\n",
    "        disc_fact = self.get_discount_factors()\n",
    "        return sum([d * self.cpn for d in disc_fact]) + (100 * disc_fact[-1])\n",
    "\n",
    "    def clean_px(self):\n",
    "        '''\n",
    "        Inputs: c_dt, maturity, cpn, yld\n",
    "        Output: dirty price\n",
    "        '''\n",
    "        next_year_frac = ([i for i in self.cpn_dates if i > self.c_dt][0] - self.c_dt).days / 365.\n",
    "        next_disc_fact = self.get_discount_factors()[0]\n",
    "        dirty_px = self.dirty_px()\n",
    "        return dirty_px - (1 - next_year_frac) * next_disc_fact * self.cpn\n",
    "\n",
    "    def dv01(self):\n",
    "        '''\n",
    "        Inputs: c_dt, maturity, cpn, yld\n",
    "        Output: dv01\n",
    "\n",
    "        val_cpn_dates = [i for i in self.cpn_dates if i > self.c_dt]\n",
    "        w = 1-(val_cpn_dates[0] - self.c_dt).days/365.\n",
    "        y = self.yld/100.\n",
    "        C = self.cpn/100.\n",
    "        N = float(len(val_cpn_dates))\n",
    "        P = self.dirty_px()/100.\n",
    "        return -1*(((1+y)**w)*((C/(y**2))*((1/((1+y)**N))-1) + N*((C/y) -1)*(1/((1+y)**(N+1))))+(w/(1+y))*P)\n",
    "        '''\n",
    "        px_base = self.dirty_px()\n",
    "        start_yld = self.yld\n",
    "        self.yld = start_yld + 0.01\n",
    "        px_up = self.dirty_px()\n",
    "        self.yld = start_yld - 0.01\n",
    "        px_down = self.dirty_px()\n",
    "        self.yld = start_yld\n",
    "        return 100 * (px_down - px_up) / 2.0\n",
    "\n",
    "    def convexity(self):\n",
    "        '''\n",
    "        Inputs: c_dt, maturity, cpn, yld\n",
    "        Output: convexity\n",
    "        val_cpn_dates = [i for i in self.cpn_dates if i > self.c_dt]\n",
    "        w = 1 - (val_cpn_dates[0] - self.c_dt).days / 365.\n",
    "        y = self.yld / 100.\n",
    "        C = self.cpn / 100.\n",
    "        N = float(len(val_cpn_dates))\n",
    "        P = self.dirty_px()\n",
    "        t1 = (-w / ((1 + y) ** 2)) * P + (w / (1 + y)) * dv01\n",
    "        t2 = (N * (N + 1 - w)) * ((1 - (C / y)) / ((1 + y) ** (N + 2 - w)))\n",
    "        t3 = (2 * C * N / (y ** 2)) / ((1 + y) ** (N + 1 - w))\n",
    "        t4 = C * (((1 + y) ** w) / (y ** 3)) * (1 - 1 / ((1 + y) ** N)) * (2 - ((w * y) / (1 + y)))\n",
    "        return (t1 + t2 - t3 + t4)/100\n",
    "        '''\n",
    "        dv01_base = self.dv01()\n",
    "        yld_base = self.yld\n",
    "        self.yld = yld_base + 0.01\n",
    "        dv01_up = self.dv01()\n",
    "        self.yld = yld_base - 0.01\n",
    "        dv01_down = self.dv01()\n",
    "        self.yld = yld_base\n",
    "        return 100 * abs(dv01_up - dv01_down) / 2.\n",
    "\n",
    "    def mod_duration(self):\n",
    "        '''\n",
    "        Inputs: c_dt, maturity, cpn, yld\n",
    "        Output: modified duration\n",
    "        '''\n",
    "        dv01 = self.dv01()\n",
    "        dirty_px = self.dirty_px()\n",
    "        return 100 * (1 / dirty_px) * dv01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yld_scenarios(bd,yld_chg):\n",
    "    '''\n",
    "    bd: A bond object as defined above\n",
    "    yld_chg: basis points to move yield up and down\n",
    "    return: list of dirty pxs,dv01,dollar convexity\n",
    "    '''\n",
    "    start_yld = bd.yld\n",
    "    yld_range = range(-yld_chg,yld_chg+1)\n",
    "    prices = []\n",
    "    dv01s = []\n",
    "    convs = []\n",
    "    for y in yld_range:\n",
    "        bd.yld = start_yld+y/100\n",
    "        prices.append(bd.dirty_px())\n",
    "        dv01s.append(bd.dv01())\n",
    "        convs.append(bd.convexity())\n",
    "    return prices,dv01s,convs\n",
    "\n",
    "def bond_scenarios(bd,t_chg,yld_chg,roll=False):\n",
    "    '''\n",
    "    :param bd: bond object\n",
    "    :param t_chg: how many years forward\n",
    "    :param y_ch: how many bp shocks\n",
    "    :param roll: roll down the yield curve\n",
    "    :return: 3 dataframes of prices,dv01s,convexities index by year, columns are yield shocks\n",
    "    '''\n",
    "    cols = range(-yld_chg,yld_chg+1)\n",
    "    px_df = pd.DataFrame(columns=cols)\n",
    "    dv_df = pd.DataFrame(columns=cols)\n",
    "    conv_df = pd.DataFrame(columns=cols)\n",
    "    start_yr = bd.c_dt.year\n",
    "    start_yld = bd.yld\n",
    "    for i in range(t_chg+1):\n",
    "        bd.yld = start_yld\n",
    "        eval_date = datetime.date(start_yr+i,bd.c_dt.month,bd.c_dt.day)\n",
    "        if roll:\n",
    "            xp = [datetime.date(j[0].year+i,j[0].month,j[0].day).toordinal() for j in aust_yld_crv]\n",
    "            fp = [k[1] for k in aust_yld_crv]\n",
    "            bd.yld = np.interp(bd.mat.toordinal(),xp,fp)\n",
    "        bd.c_dt = datetime.date(start_yr+i,bd.c_dt.month,bd.c_dt.day)\n",
    "        prices, dv01s, convs = yld_scenarios(bd,yld_chg)\n",
    "        px_df.loc[eval_date] = prices\n",
    "        dv_df.loc[eval_date] = dv01s\n",
    "        conv_df.loc[eval_date] = convs\n",
    "    return px_df,dv_df,conv_df\n",
    "\n",
    "def flattener_scenarios(bd1,bd2):\n",
    "    '''\n",
    "\n",
    "    :param bd1: px,dv01,conv for bond1 - short this bond\n",
    "    :param bd2: px,dv01,conv for bond2 - long this bond\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    scalar_1 = -100/bd1[1][0][0]\n",
    "    scalar_2 = 100/bd2[1][0][0]\n",
    "\n",
    "    px_df_30y, dv_df_30y, conv_df_30y = bd1[0]*scalar_1,bd1[1]*scalar_1,bd1[2]*scalar_1/100\n",
    "    px_df_100y, dv_df_100y, conv_df_100y = bd2[0]*scalar_2,bd2[1]*scalar_2,bd2[2]*scalar_2/100\n",
    "    pnl_30y = 100*(px_df_30y - px_df_30y[0][0])\n",
    "    pnl_100y = 100*(px_df_100y - px_df_100y[0][0])\n",
    "    total_pnl = pnl_30y+pnl_100y\n",
    "    total_dv = dv_df_30y+dv_df_100y\n",
    "    total_conv = conv_df_30y+conv_df_100y\n",
    "    return  total_pnl,total_dv,total_conv\n",
    "\n",
    "def x_intercept(total_df):\n",
    "    '''\n",
    "    find the x-intercept of incremental scenarios\n",
    "    '''\n",
    "    cols = list(total_df.index)\n",
    "    input = 0\n",
    "    intercepts = []\n",
    "    for c in cols:\n",
    "        df = total_df.T[c]\n",
    "        df.iloc[(df-input).abs().argsort()[:2]]\n",
    "        intercepts.append((c,sum(df.iloc[(df-input).abs().argsort()[:2]].index)/2.))\n",
    "    return intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "bond1 = Bond(datetime.date(2020,3,20),datetime.date(2051,3,20),0.75, 0.369605)\n",
    "bond2 = Bond(datetime.date(2020,6,30),datetime.date(2120,6,30),0.85, 0.806103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_sc1 = bond_scenarios(bond1,5,400)\n",
    "bond_sc2 = bond_scenarios(bond2,5,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pnl,total_dv,total_conv = flattener_scenarios(bond_sc1,bond_sc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_label = 'Yield Shift (bps)'\n",
    "y_label = \"PnL (€k)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure()\n",
    "total_pnl[range(-150,151)].loc[datetime.date(2021,8,6)].T.plot()\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)\n",
    "plt.title('Instantaneous PnL Scenario')\n",
    "f.savefig('pnl_base.png',dpi=120)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-spirit",
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = plt.figure()\n",
    "(0.5*total_conv[range(-200,200)].loc[datetime.date(2021,8,6)].T).plot()\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)\n",
    "plt.title('Incremental Convexity PnL')\n",
    "f2.savefig('conv_base.png',dpi=120)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dv[range(-5,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_sc2[2].T.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-colleague",
   "metadata": {},
   "outputs": [],
   "source": [
    "bond3 = Bond(datetime.date(2020,3,20),datetime.date(2051,3,20),0.75, 0.369605)\n",
    "bond4 = Bond(datetime.date(2020,6,30),datetime.date(2120,6,30),0.85, 0.806103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_sc3 = bond_scenarios(bond3,5,400,True)\n",
    "bond_sc4 = bond_scenarios(bond4,5,400,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pnl_2,total_dv_2,total_conv_2 = flattener_scenarios(bond_sc3,bond_sc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_intercept(total_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-maximum",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_intercept(total_conv_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_conv = pd.DataFrame(columns=['Flat','Roll'])\n",
    "comp_conv['Flat'] = total_conv[0]\n",
    "comp_conv['Roll'] = total_conv_2[0]\n",
    "comp_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-tolerance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-maker",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
